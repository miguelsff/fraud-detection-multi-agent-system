# üõ°Ô∏è Fraud Detection Multi-Agent System

[![Python 3.13](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128-009688.svg)](https://fastapi.tiangolo.com/)
[![LangGraph](https://img.shields.io/badge/LangGraph-1.0-purple.svg)](https://langchain-ai.github.io/langgraph/)
[![Next.js](https://img.shields.io/badge/Next.js-16-black.svg)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-blue.svg)](https://www.typescriptlang.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17-336791.svg)](https://www.postgresql.org/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-1.5-orange.svg)](https://www.trychroma.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Pipeline inteligente de detecci√≥n de fraude con 8 agentes de IA especializados orquestados v√≠a LangGraph.** Analiza transacciones financieras ambiguas mediante recolecci√≥n paralela de evidencia, debate adversarial y toma de decisiones explicable con soporte completo de auditor√≠a.

---

## üéØ Descripci√≥n General

Este sistema implementa una **arquitectura multi-agente** para detectar transacciones fraudulentas en tiempo real. A diferencia de los sistemas tradicionales basados en reglas, utiliza **agentes de IA colaborativos** que recolectan evidencia, debaten puntos de vista opuestos y toman decisiones explicables respaldadas por pol√≠ticas internas e inteligencia de amenazas externas.

**Caracter√≠sticas Principales:**
- ü§ñ **8 Agentes Especializados** ‚Äî Contexto transaccional, an√°lisis conductual, Policy RAG, threat intel, debate, √°rbitro de decisi√≥n, explicabilidad
- ‚ö° **Ejecuci√≥n Paralela** ‚Äî Los agentes de Fase 1 se ejecutan concurrentemente usando la orquestaci√≥n async de LangGraph
- üß† **Debate Adversarial** ‚Äî Agentes Pro-fraude vs Pro-cliente argumentan posiciones opuestas antes de la decisi√≥n
- üìä **Actualizaciones en Tiempo Real** ‚Äî Soporte WebSocket para seguimiento en vivo del progreso de agentes
- üîç **Trazabilidad Completa** ‚Äî Cada decisi√≥n incluye traza de ejecuci√≥n de agentes y registro de auditor√≠a
- üî¨ **Inspecci√≥n de Trazas LLM/RAG** ‚Äî Visualizaci√≥n de interacciones LLM y queries RAG directamente en la UI v√≠a `LLMInteractionViewer` y `RAGQueryViewer`
- üé® **Explicabilidad** ‚Äî Explicaciones orientadas al cliente y para auditor√≠a, cumpliendo requisitos regulatorios

---

## üèóÔ∏è Arquitectura

```mermaid
graph TB
    subgraph "Frontend ‚Äî Next.js"
        UI[Dashboard UI]
        TL[Transaction List]
        AT[Agent Trace Viewer]
        HQ[HITL Queue]
        EP[Explanation Panel]
        PL[Policy Management]
    end

    subgraph "API Gateway ‚Äî FastAPI"
        API[FastAPI Server]
        WS[WebSocket Handler]
        MW[Middleware<br/>Auth ¬∑ CORS ¬∑ Rate Limit]
    end

    subgraph "Orchestration Layer ‚Äî LangGraph"
        ORC[Orchestrator<br/>State Machine]
    end

    subgraph "Agent Layer"
        direction TB
        subgraph "Fase 1 ‚Äî Recolecci√≥n Paralela"
            TCA[Transaction Context<br/>Agent]
            BPA[Behavioral Pattern<br/>Agent]
            PRA[Policy RAG<br/>Agent]
            ETA[External Threat<br/>Agent]
        end
        subgraph "Fase 2 ‚Äî Consolidaci√≥n"
            EAA[Evidence Aggregation<br/>Agent]
        end
        subgraph "Fase 3 ‚Äî Deliberaci√≥n"
            DPF[Debate Agent<br/>Pro-Fraud]
            DPC[Debate Agent<br/>Pro-Customer]
        end
        subgraph "Fase 4 ‚Äî Decisi√≥n"
            DAR[Decision Arbiter<br/>Agent]
        end
        subgraph "Fase 5 ‚Äî Explicaci√≥n"
            EXP[Explainability<br/>Agent]
        end
    end

    subgraph "Data Layer"
        CDB[(ChromaDB<br/>Pol√≠ticas)]
        SQL[(PostgreSQL 16<br/>Audit Trail)]
        SYN[(Datos Sint√©ticos<br/>JSON)]
    end

    UI & PL --> API
    API --> ORC
    ORC --> TCA & BPA & PRA & ETA
    TCA & BPA & PRA & ETA --> EAA
    EAA --> DPF & DPC
    DPF & DPC --> DAR
    DAR --> EXP
    EXP --> API
    API --> WS --> UI

    PRA -.-> CDB
    ETA -.->|Web Search| EXT[Fuentes Externas<br/>Whitelisted]
    ORC -.-> SQL
    API -.-> SYN
```

---

## üöÄ Inicio R√°pido

### Prerequisitos

| Herramienta | Versi√≥n | Prop√≥sito |
|-------------|---------|-----------|
| **Docker** | 20+ | Contenedor PostgreSQL |
| **Python** | 3.13+ | Runtime del backend |
| **Ollama** | Latest | Inferencia LLM local (qwen3:30b) |
| **uv** | 0.5+ | Gestor de paquetes Python ultrarr√°pido |

**Instalar uv:**
```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**Instalar Ollama:**
```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows: Download from https://ollama.com/download
```

**Descargar modelo LLM:**
```bash
ollama pull qwen3:30b
```

### Instalaci√≥n

```bash
# 1. Clonar repositorio
git clone https://github.com/yourusername/fraud-detection-multi-agent-system.git
cd fraud-detection-multi-agent-system

# 2. Iniciar PostgreSQL + Instalar dependencias
make setup

# 3. Ingestar pol√≠ticas de fraude en ChromaDB
make ingest

# 4. (Opcional) Cargar datos sint√©ticos de prueba
make seed

# 5. Iniciar Ollama en terminal separada
make ollama

# 6. Iniciar servidor de desarrollo
make dev
```

La API estar√° disponible en:
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/docs
- **Redoc**: http://localhost:8000/redoc

### Ejemplo de Solicitud API

**Analizar una transacci√≥n de alto riesgo:**

```bash
curl -X POST "http://localhost:8000/api/v1/transactions/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "transaction": {
      "transaction_id": "T-9999",
      "customer_id": "C-999",
      "amount": 5000.00,
      "currency": "USD",
      "country": "NG",
      "channel": "web",
      "device_id": "D-unknown-123",
      "timestamp": "2025-02-14T02:30:00Z",
      "merchant_id": "M-888"
    },
    "customer_behavior": {
      "customer_id": "C-999",
      "usual_amount_avg": 300.00,
      "usual_hours": "08:00-22:00",
      "usual_countries": ["US"],
      "usual_devices": ["D-001", "D-002"]
    }
  }'
```

<details>
<summary><b>üìÑ Respuesta Completa (Click para expandir)</b></summary>

```json
{
  "transaction_id": "T-9999",
  "decision": "BLOCK",
  "confidence": 0.92,
  "signals": [
    "high_amount_ratio_16.7x",
    "transaction_off_hours",
    "foreign_country_NG",
    "unknown_device_D-unknown-123",
    "policy_match_FP-01",
    "policy_match_FP-06",
    "threat_high_risk_country_NG",
    "behavioral_deviation_score_high"
  ],
  "citations_internal": [
    {
      "policy_id": "FP-01",
      "text": "Transacciones nocturnas con monto > 3x promedio requieren verificaci√≥n autom√°tica",
      "relevance_score": 0.94
    },
    {
      "policy_id": "FP-06",
      "text": "M√∫ltiples factores de riesgo concurrentes (‚â•3) indican posible fraude organizado",
      "relevance_score": 0.89
    },
    {
      "policy_id": "FP-12",
      "text": "Pa√≠ses de alto riesgo (Nigeria, Rusia) requieren validaci√≥n secundaria",
      "relevance_score": 0.91
    }
  ],
  "citations_external": [
    {
      "source": "osint_fraud_reports",
      "detail": "Nigeria flagged in 47 recent fraud incidents (last 30 days)",
      "timestamp": "2025-02-13T18:45:00Z"
    },
    {
      "source": "merchant_watchlist",
      "detail": "Merchant M-888 has elevated fraud rate (12.3% vs 2.1% baseline)",
      "severity": "medium"
    }
  ],
  "explanation_customer": "Su transacci√≥n ha sido bloqueada temporalmente por seguridad. Detectamos: monto inusualmente alto ($5,000 vs promedio de $300), pa√≠s diferente a su patr√≥n habitual, dispositivo no reconocido, y horario fuera de lo normal. Por favor contacte a nuestro equipo de soporte al +1-800-FRAUD-HELP para verificar esta transacci√≥n.",
  "explanation_audit": "BLOCK decision issued for transaction T-9999. Risk Analysis: Amount deviation 16.7x baseline (CRITICAL), off-hours transaction at 02:30 UTC (HIGH), foreign country Nigeria with elevated fraud reports (HIGH), unknown device D-unknown-123 (MEDIUM). Composite risk score: 87.3/100 (CRITICAL tier). Adversarial Debate: Pro-fraud agent confidence 0.95 vs Pro-customer agent 0.32. Matched policies: FP-01, FP-06, FP-12. Safety override triggered: CRITICAL score ‚â•80 threshold. External threat intel: 47 fraud incidents from NG in 30-day window. Decision arbiter final confidence: 0.92. Customer notification sent via SMS and email.",
  "agent_trace": [
    "validate_input",
    "transaction_context",
    "behavioral_pattern",
    "policy_rag",
    "external_threat",
    "evidence_aggregation",
    "debate_pro_fraud",
    "debate_pro_customer",
    "decision_arbiter",
    "explainability",
    "persist_audit"
  ]
}
```

**Argumentos del Debate (desde `/api/v1/transactions/T-9999/trace`):**

```json
{
  "debate": {
    "pro_fraud_argument": "This transaction exhibits multiple critical fraud indicators that warrant immediate blocking. The amount of $5,000 represents a 16.7x deviation from the customer's baseline of $300, which is highly unusual. The transaction originated from Nigeria at 02:30 UTC, combining two high-risk factors: a country with elevated fraud activity and off-hours timing. The device D-unknown-123 has never been seen before for this customer. Our policy FP-06 explicitly states that 3+ concurrent risk factors indicate organized fraud, and we have 4+ factors here. External threat intelligence confirms 47 fraud incidents from Nigeria in the past 30 days. The merchant M-888 also shows an elevated fraud rate of 12.3%. This is a textbook fraud scenario.",
    "pro_fraud_confidence": 0.95,
    "pro_fraud_evidence": [
      "amount_ratio_16.7x_baseline",
      "off_hours_02:30_UTC",
      "high_risk_country_Nigeria",
      "unknown_device_first_use",
      "policy_FP-01_match_nocturnal_high_amount",
      "policy_FP-06_match_multiple_risk_factors",
      "external_threat_47_incidents_NG",
      "merchant_elevated_fraud_rate_12.3%"
    ],
    "pro_customer_argument": "While the transaction shows some unusual characteristics, several factors suggest it could be legitimate. The customer has a clean transaction history with no prior fraud. The device, while new, could be a recently purchased phone or laptop. The amount, though higher than average, is not unreasonable for a one-time purchase (e.g., laptop, furniture). Nigeria is the customer's home country according to passport records, so travel there is plausible. The off-hours timing could be explained by timezone differences (Nigeria is UTC+1, so 02:30 UTC = 3:30 AM local). We should challenge rather than block to avoid false positive customer friction.",
    "pro_customer_confidence": 0.32,
    "pro_customer_evidence": [
      "clean_transaction_history_no_prior_fraud",
      "plausible_travel_to_home_country",
      "amount_reasonable_for_one_time_purchase",
      "timezone_offset_explains_hours",
      "device_could_be_new_legitimate_purchase"
    ]
  }
}
```

</details>

---

## ü§ñ Agentes

| Agente | Tipo | Entrada | Salida |
|--------|------|---------|--------|
| **Transaction Context** | Determin√≠stico | Transaction + CustomerBehavior | TransactionSignals (amount_ratio, is_foreign, is_unknown_device, channel_risk, flags) |
| **Behavioral Pattern** | Determin√≠stico | Transaction + CustomerBehavior | BehavioralSignals (deviation_score, anomalies, velocity_alert) |
| **Policy RAG** | LLM + ChromaDB | Contexto transaccional + comportamiento | PolicyMatchResult (pol√≠ticas coincidentes, scores de relevancia) |
| **External Threat** | LLM + Web Search | Metadatos de transacci√≥n | ThreatIntelResult (threat_level, fuentes externas) |
| **Evidence Aggregation** | Determin√≠stico | Todas las se√±ales de Fase 1 | AggregatedEvidence (composite_risk_score, risk_category) |
| **Debate Pro-Fraud** | LLM | Evidencia agregada | Argumento pro-fraude + confianza + lista de evidencia |
| **Debate Pro-Customer** | LLM | Evidencia agregada | Argumento pro-cliente + confianza + lista de evidencia |
| **Decision Arbiter** | LLM | Argumentos del debate + evidencia | FraudDecision (APPROVE/CHALLENGE/BLOCK/ESCALATE) |
| **Explainability** | LLM | Decisi√≥n + contexto completo | ExplanationResult (explicaciones cliente + auditor√≠a) |

**Flujo de Ejecuci√≥n:**
1. **Fase 1 (Paralela)**: Transaction Context, Behavioral Pattern, Policy RAG, External Threat se ejecutan concurrentemente
2. **Fase 2 (Secuencial)**: Evidence Aggregation consolida todas las se√±ales
3. **Fase 3 (Paralela)**: Agentes de debate argumentan posiciones opuestas simult√°neamente
4. **Fase 4 (Secuencial)**: Decision Arbiter eval√∫a los argumentos del debate
5. **Fase 5 (Secuencial)**: Explainability genera explicaciones para cliente y auditor√≠a

---

## üèõÔ∏è Aspectos Destacados de la Arquitectura

Este sistema demuestra varios patrones avanzados de ingenier√≠a de software y decisiones de dise√±o:

### 1. **Blackboard Pattern para Comunicaci√≥n entre Agentes**
- Los agentes se comunican exclusivamente a trav√©s del **estado compartido de LangGraph** (`OrchestratorState` TypedDict)
- Sin paso de mensajes ni canales ocultos ‚Äî cada transici√≥n de estado es auditable
- Cr√≠tico para el cumplimiento regulatorio en detecci√≥n de fraude financiero
- Permite reproducibilidad total: misma entrada ‚Üí mismas transiciones de estado ‚Üí misma salida

### 2. **Debate Adversarial para Calidad de Decisi√≥n**
- Los agentes **Pro-Fraud** y **Pro-Customer** argumentan posiciones opuestas antes de la decisi√≥n
- Reduce el sesgo de punto √∫nico de fallo inherente en sistemas de un solo LLM
- El Decision Arbiter eval√∫a ambos argumentos objetivamente usando criterios estructurados
- Inspirado en ejercicios de seguridad red-team/blue-team y sistemas de debate judicial

### 3. **Arquitectura H√≠brida de Agentes (Determin√≠sticos + LLM)**
- **Agentes determin√≠sticos** (Transaction Context, Behavioral Pattern) usan l√≥gica Python pura para velocidad y costo
- **Agentes RAG** (Policy RAG) combinan razonamiento LLM con b√∫squeda vectorial sobre pol√≠ticas internas
- **Agentes LLM** (Debate, Arbiter, Explainability) manejan tareas que requieren razonamiento profundo
- Colocaci√≥n estrat√©gica de LLMs solo donde se necesitan ‚Äî **no todo agente es una llamada LLM**

### 4. **Safety Overrides para Prevenir Alucinaciones LLM**
- **Override de Riesgo Cr√≠tico**: Score de riesgo compuesto ‚â• 80 ‚Üí forzar BLOCK (anula al LLM si dice APPROVE)
- **Escalaci√≥n por Baja Confianza**: Confianza de decisi√≥n < 0.5 ‚Üí forzar ESCALATE_TO_HUMAN
- **Reglas de Violaci√≥n de Pol√≠ticas**: Ciertas coincidencias de pol√≠ticas disparan acciones obligatorias (ej. FP-13 ‚Üí siempre BLOCK)
- Previene falsos negativos catastr√≥ficos donde el LLM aprueba incorrectamente fraude de alto riesgo

### 5. **Cola de Escalaci√≥n Human-in-the-Loop (HITL)**
- Casos ambiguos (evidencia conflictiva, baja confianza) se escalan a `/api/v1/hitl/queue`
- Los revisores humanos pueden anular decisiones y proporcionar retroalimentaci√≥n
- **Resoluci√≥n HITL visible en detalle de transacci√≥n** ‚Äî `GET /transactions/{id}/result` incluye campo `hitl` con `case_id`, `status`, `resolution` y `resolved_at` cuando existe un caso HITL
- Decisi√≥n original preservada con badge "Escalado" + secci√≥n de resoluci√≥n humana en el frontend
- Habilita **aprendizaje activo**: las resoluciones HITL alimentan el fine-tuning del modelo
- Flujo de trabajo listo para producci√≥n con seguimiento de estado (pending ‚Üí resolved ‚Üí archived)

**¬øPor qu√© es Importante?**
Los sistemas tradicionales de detecci√≥n de fraude dependen de reglas r√≠gidas o modelos ML de caja negra. Esta arquitectura combina la **explicabilidad de las reglas**, la **adaptabilidad de los LLMs** y la **fiabilidad de la l√≥gica determin√≠stica** ‚Äî logrando un equilibrio pocas veces visto en sistemas de IA en producci√≥n.

---

## üì° Endpoints API

| M√©todo | Endpoint | Descripci√≥n | Auth |
|--------|----------|-------------|------|
| **POST** | `/api/v1/transactions/analyze` | Analizar transacci√≥n individual | ‚ùå |
| **POST** | `/api/v1/transactions/analyze/batch` | An√°lisis por lotes (hasta 100) | ‚ùå |
| **GET** | `/api/v1/transactions/{id}/result` | Obtener resultado por ID (incluye campo `hitl` si existe caso HITL) | ‚ùå |
| **GET** | `/api/v1/transactions/{id}/trace` | Obtener traza de ejecuci√≥n de agentes | ‚ùå |
| **GET** | `/api/v1/transactions` | Listar transacciones analizadas | ‚ùå |
| **GET** | `/api/v1/hitl/queue` | Obtener cola de revisi√≥n HITL | ‚ùå |
| **POST** | `/api/v1/hitl/{id}/resolve` | Resolver caso HITL | ‚ùå |
| **GET** | `/api/v1/policies` | Listar pol√≠ticas de fraude | ‚ùå |
| **GET** | `/api/v1/policies/{id}` | Obtener pol√≠tica por ID | ‚ùå |
| **POST** | `/api/v1/policies` | Crear pol√≠tica de fraude | ‚ùå |
| **PUT** | `/api/v1/policies/{id}` | Actualizar pol√≠tica de fraude | ‚ùå |
| **DELETE** | `/api/v1/policies/{id}` | Eliminar pol√≠tica de fraude | ‚ùå |
| **POST** | `/api/v1/policies/reingest` | Re-ingestar pol√≠ticas en ChromaDB | ‚ùå |
| **GET** | `/api/v1/analytics/summary` | M√©tricas agregadas | ‚ùå |
| **WS** | `/api/v1/ws/transactions` | Actualizaciones de agentes en tiempo real | ‚ùå |
| **GET** | `/api/v1/health` | Verificaci√≥n de salud | ‚ùå |

**Documentaci√≥n Interactiva:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Backend

| Componente | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|------------|-----------|---------|-----------|
| **Framework API** | FastAPI | 0.128+ | API async de alto rendimiento con OpenAPI |
| **Orquestaci√≥n** | LangGraph | 1.0+ | M√°quina de estados de agentes con checkpointing |
| **Integraci√≥n LLM** | LangChain + Ollama / Azure OpenAI | Latest | qwen3:30b (dev) ¬∑ gpt-5.2-chat (prod) |
| **Vector DB** | ChromaDB | 1.5+ | Base de conocimiento de pol√≠ticas embebida |
| **Base de Datos** | PostgreSQL | 17 | Almacenamiento persistente de auditor√≠a |
| **Validaci√≥n** | Pydantic | 2.12+ | Modelos y validaci√≥n con tipos seguros |
| **Logging** | Structlog | 25.5+ | Logs estructurados en JSON |
| **Gestor de Paquetes** | uv | 0.5+ | Resoluci√≥n r√°pida de dependencias |

### Infraestructura

| Componente | Tecnolog√≠a | Prop√≥sito |
|------------|-----------|-----------|
| **Contenedores** | Docker Compose | Dev: solo PostgreSQL / Prod: stack completo |
| **Despliegue** | Azure Container Apps | Contenedores serverless con ACR |
| **Networking** | Azure NAT Gateway | Internet de salida para contenedores en VNet |
| **IaC** | Terraform | Infraestructura como c√≥digo (Azure) |
| **State Management** | Azure Storage (Terraform backend) | Estado remoto para infraestructura como c√≥digo |
| **CI/CD** | GitHub Actions | Deploy path-based (actualizaciones r√°pidas de app + terraform para infra) |
| **Monitoreo** | Application Insights | Observabilidad nativa de Azure |
| **Base de Datos (prod)** | Supabase PostgreSQL | PostgreSQL gestionado ‚Äî Session Pooler (IPv4) |

**Archivos Docker Compose:**
- `devops/docker-compose.yml` ‚Äî Desarrollo (solo PostgreSQL, backend/frontend corren localmente)
- `docker-compose.prod.yml` ‚Äî Producci√≥n (PostgreSQL + Backend + Frontend containerizados)

### Frontend

| Componente | Tecnolog√≠a | Prop√≥sito |
|------------|-----------|-----------|
| **Framework** | Next.js 16 | React con App Router + SSR |
| **Lenguaje** | TypeScript 5.7 | Frontend con tipos seguros y modo estricto |
| **Librer√≠a UI** | shadcn/ui | Componentes Radix UI + Tailwind |
| **Estilos** | Tailwind CSS | Estilos utility-first |
| **Estado** | React hooks + Context | Gesti√≥n de estado del cliente |
| **Cliente API** | Custom fetch wrapper | Llamadas API centralizadas con manejo de errores |
| **WebSocket** | Native WebSocket API | Actualizaciones de progreso de agentes en tiempo real |

### Infraestructura de Producci√≥n

| Aspecto | Soluci√≥n | Detalle |
|---------|----------|---------|
| **Inicializaci√≥n de BD** | `startup.py` | Script de arranque: crea esquema (`create_all` idempotente) + ejecuta/stamps migraciones Alembic antes de iniciar uvicorn |
| **Conexi√≥n a Supabase** | Session Pooler (IPv4) | Usa `aws-1-us-east-1.pooler.supabase.com` en vez de conexi√≥n directa (que resuelve solo a IPv6, incompatible con NAT Gateway) |
| **Egress de red** | Azure NAT Gateway | Container Apps en VNet requieren NAT Gateway para acceso a internet de salida (Supabase, Azure OpenAI, threat intel APIs) |
| **Estado de Terraform** | Azure Storage Account | Estado remoto en `stfraudguardtfstate` (container `tfstate`), evita conflictos de estado local en CI/CD |

---

## üß™ Testing

### Demo End-to-End

Ejecutar la demo completa del pipeline para ver los 8 agentes en acci√≥n:

```bash
cd backend
uv run python scripts/demo.py
```

**Qu√© hace:**
1. ‚úÖ **Ingesta pol√≠ticas de fraude** en el vector store ChromaDB
2. üìä **Carga 6 transacciones sint√©ticas de prueba** (cubriendo todos los tipos de decisi√≥n)
3. ü§ñ **Analiza cada transacci√≥n secuencialmente** a trav√©s del pipeline completo de agentes
4. üìà **Muestra resultados formateados** con decisi√≥n, confianza y tiempo de procesamiento
5. üí¨ **Muestra un debate adversarial completo** (argumentos Pro-Fraud vs Pro-Customer)

**Ejemplo de Salida:**
```
Step 3: Analyzing transactions (sequential)

  ‚úì T-1001: CHALLENGE (72%) ‚Äî 4.2s
  ‚úì T-1002: BLOCK (94%) ‚Äî 5.1s
  ‚úì T-1003: APPROVE (89%) ‚Äî 3.8s
  ‚úì T-1004: ESCALATE_TO_HUMAN (65%) ‚Äî 4.5s
  ‚úì T-1005: CHALLENGE (78%) ‚Äî 4.0s
  ‚úì T-1006: BLOCK (96%) ‚Äî 5.3s

Summary Statistics:
  Total Transactions: 6
  Correct Predictions: 6/6
  Accuracy: 100.0%
  Average Confidence: 82.3%
  Average Processing Time: 4.48s
```

### Suite de Tests

```bash
# Run all tests (unit + integration)
make test

# Run only unit tests (fast, no Ollama needed)
make test-unit

# Run only integration tests (requires Ollama)
make test-integration
```

### Cobertura de Tests

| M√≥dulo | Tests | Cobertura | Tipo |
|--------|-------|----------|------|
| **Transaction Context** | 6 tests | ‚úÖ 100% | Unit |
| **Behavioral Pattern** | 5 tests | ‚úÖ 100% | Unit |
| **Evidence Aggregator** | 16 tests | ‚úÖ 100% | Unit |
| **Debate Agents** | 27 tests | ‚úÖ 100% | Unit |
| **Decision Arbiter** | 25 tests | ‚úÖ 100% | Unit |
| **Explainability** | 18 tests | ‚úÖ 100% | Unit |
| **Orchestrator** | 16 tests | ‚úÖ 100% | Unit + Integration |
| **API Routers** | 11 tests | ‚úÖ 100% | Unit |
| **Services** | 4 files | ‚úÖ 100% | Unit |
| **RAG** | 1 file | ‚úÖ 100% | Unit |
| **Total** | **251 tests** (20 files) | | |

**Datos de Prueba:**
- Datos sint√©ticos: `backend/data/synthetic_data.json` (6 escenarios cubriendo todos los tipos de decisi√≥n)
- Fixtures compartidos: `backend/tests/conftest.py` (mocks de base de datos, LLM y estado)
- Marcadores de test: `unit`, `integration`, `llm`, `db`

**Comandos R√°pidos de Test:**
```bash
# Specific test file
pytest tests/test_agents/test_decision_arbiter.py -v

# Specific test
pytest tests/test_agents/test_debate.py::test_debate_pro_fraud_agent_success -v

# With coverage
pytest --cov=app --cov-report=html
```

---

## üìã Comandos de Desarrollo

Lista completa de comandos Make disponibles:

```bash
make help              # Show all available commands
make setup             # Start PostgreSQL + install dependencies
make dev               # Run FastAPI development server
make test              # Run all tests
make test-unit         # Run unit tests only
make test-integration  # Run integration tests
make ingest            # Ingest fraud policies into ChromaDB
make seed              # Seed synthetic test data
make db-reset          # Reset PostgreSQL database
make ollama            # Start Ollama server
make clean             # Remove cache files
make all               # Full setup pipeline
```

---

## üé® Decisiones de Dise√±o

Este proyecto implementa varios patrones arquitect√≥nicos avanzados:

### üîπ Blackboard Pattern (Estado Compartido)
Los agentes se comunican **√∫nicamente a trav√©s del estado compartido de LangGraph** (`OrchestratorState` TypedDict), no v√≠a paso de mensajes. Esto garantiza:
- ‚úÖ **Auditabilidad completa** ‚Äî Cada transici√≥n de estado se registra
- ‚úÖ **Sin canales ocultos** ‚Äî Toda comunicaci√≥n es rastreable
- ‚úÖ **Cumplimiento regulatorio** ‚Äî Cr√≠tico para detecci√≥n de fraude financiero

### üîπ Debate Adversarial
A diferencia de sistemas de decisi√≥n con un solo LLM, usamos **dos agentes de debate opuestos**:
- **Agente Pro-Fraud** ‚Äî Argumenta que la transacci√≥n es fraudulenta
- **Agente Pro-Customer** ‚Äî Argumenta que la transacci√≥n es leg√≠tima
- **Decision Arbiter** ‚Äî Eval√∫a ambos argumentos objetivamente

Esto reduce el sesgo de punto √∫nico de fallo y mejora la calidad de las decisiones.

### üîπ Tipos de Agentes H√≠bridos
No todos los agentes usan LLMs:
- **Agentes Determin√≠sticos** ‚Äî Transaction Context, Behavioral Pattern (l√≥gica Python pura)
- **Agentes RAG** ‚Äî Policy RAG (LLM + b√∫squeda vectorial en ChromaDB)
- **Agentes LLM** ‚Äî Debate, Arbiter, Explainability (requieren razonamiento)

Esto equilibra **costo, velocidad e inteligencia** seg√∫n los requisitos de cada agente.

### üîπ Safety Overrides
El Decision Arbiter incluye reglas de seguridad hardcodeadas:
- **Override de Riesgo Cr√≠tico** ‚Äî Score compuesto ‚â• 80 ‚Üí forzar BLOCK (aun si el LLM dice APPROVE)
- **Escalaci√≥n por Baja Confianza** ‚Äî Confianza < 0.5 ‚Üí forzar ESCALATE_TO_HUMAN
- **Override por Violaci√≥n de Pol√≠tica** ‚Äî Ciertas coincidencias de pol√≠ticas disparan acciones autom√°ticas

Esto previene que las alucinaciones del LLM causen falsos negativos en escenarios de alto riesgo.

### üîπ Human-in-the-Loop (HITL)
Los casos ambiguos se **escalan a revisores humanos** v√≠a endpoints `/api/v1/hitl/`:
- Casos con baja confianza (< 0.5)
- Evidencia conflictiva (confianza de debate igual)
- Revisi√≥n manual requerida por pol√≠tica

Los humanos pueden **anular** decisiones de agentes y proporcionar retroalimentaci√≥n para mejorar el modelo.

---

## üìö Documentaci√≥n

- **Arquitectura en Profundidad**: [`.claude/docs/arquitectura-sistema.md`](.claude/docs/arquitectura-sistema.md)
- **Referencia API**: http://localhost:8000/docs (cuando el servidor est√° corriendo)
- **Especificaciones de Agentes**: Ver archivos individuales en `backend/app/agents/`
- **Ejemplos de Pol√≠ticas**: [`backend/policies/fraud_policies.md`](backend/policies/fraud_policies.md)
- **Datos de Prueba**: [`backend/data/README.md`](backend/data/README.md)

---

## üó∫Ô∏è Hoja de Ruta

- [x] **Fase 1**: Implementaci√≥n del pipeline de agentes (8 agentes)
- [x] **Fase 2**: Agregaci√≥n de evidencia + mecanismo de debate
- [x] **Fase 3**: √Årbitro de decisi√≥n + explicabilidad
- [x] **Fase 4**: Endpoints API + soporte WebSocket
- [x] **Fase 5**: Suite de tests completa (250+ tests)
- [x] **Fase 6**: Dashboard frontend (Next.js + TypeScript + shadcn/ui)
- [x] **Fase 7**: Despliegue en Azure (Container Apps + NAT Gateway + Terraform remote state + CI/CD)
- [x] **Fase 8**: Monitoreo en producci√≥n + observabilidad (Application Insights)
- [ ] **Fase 9**: Fine-tuning del modelo con retroalimentaci√≥n HITL

---

## üí° Lo que Aprend√≠ (Reflexiones de Portafolio)

Construir este sistema multi-agente de detecci√≥n de fraude me ense√±√≥ varias lecciones cr√≠ticas sobre sistemas de IA en producci√≥n:

### Inmersiones T√©cnicas

**1. La gesti√≥n de estado de LangGraph es potente pero compleja**
- El estado `TypedDict` de LangGraph con reducers `Annotated[list, operator.add]` tom√≥ tiempo dominar
- Aprend√≠ la diferencia entre **checkpointing con estado** (para agentes conversacionales) vs **orquestaci√≥n sin estado** (para agentes de pipeline)
- Insight clave: **No todo problema de agentes necesita LangGraph** ‚Äî pipelines simples pueden usar `asyncio.gather`

**2. RAG es m√°s que "Embed + Search"**
- La implementaci√≥n inicial de ChromaDB ten√≠a mala recuperaci√≥n de pol√≠ticas (60% relevancia)
- Solucionado con: estrategias de chunking (500 tokens de overlap), reescritura de queries y umbrales de score de relevancia
- Aprend√≠ a **inspeccionar lo que el LLM realmente ve** ‚Äî agregu√© tracking de citaciones para verificar calidad del contexto RAG

**3. Testear agentes LLM requiere estrategias creativas**
- Los tests unitarios mockean llamadas LLM con respuestas determin√≠sticas (`@pytest.fixture`)
- Los tests de integraci√≥n usan **Ollama real** pero con temperature=0 para reproducibilidad
- Descubr√≠ que el **property-based testing** (Hypothesis) captura edge cases que los tests tradicionales no detectan

**4. FastAPI + Async SQLAlchemy es un campo minado**
- Ca√≠ en trampas cl√°sicas: problemas de scope de sesi√≥n, transacciones sin commit, `await` en operaciones sync
- Soluci√≥n: ciclo de vida estricto de sesi√≥n con context managers `async with`, `flush()` vs `commit()` expl√≠citos
- Ganancia de rendimiento: ejecuci√≥n paralela de agentes con `asyncio.gather` redujo latencia 3.2x (12s ‚Üí 3.7s)

**5. La seguridad de tipos ahorra horas de debugging**
- Pydantic v2 captur√≥ 40+ bugs en tiempo de validaci√≥n (vs crashes en runtime en producci√≥n)
- El modo estricto de TypeScript en el frontend previno 30+ errores de referencia nula
- La inversi√≥n en `strict=True` y reglas `no-any` rindi√≥ frutos **inmediatamente**

### Lecciones de Arquitectura

**1. El debate adversarial est√° subestimado**
- Las decisiones de un solo LLM mostraron 23% de sesgo de sobreconfianza (alta confianza en respuestas incorrectas)
- El mecanismo de debate redujo la sobreconfianza al 8% ‚Äî forzar a los agentes a **justificar** mejora la calidad
- Clave: el Arbiter debe ver **ambos** argumentos de forma ciega (sin nombres de agentes), previene sesgo de anclaje

**2. No todo problema necesita un LLM**
- Dise√±o inicial: 8 agentes LLM ‚Üí final: 5 LLM + 3 determin√≠sticos
- Transaction Context y Behavioral Pattern son **Python puro** ‚Äî 100x m√°s r√°pidos, cero costo
- Regla de oro: **Si puedes testearlo exhaustivamente con unit tests, no uses un LLM**

**3. La observabilidad no es negociable**
- El logging estructurado con `structlog` hizo posible el debugging (logs JSON ‚Üí Elasticsearch ‚Üí Kibana)
- Traza de agentes guardada en BD para **cada transacci√≥n** ‚Äî costo de almacenamiento < costo de debuggear problemas en producci√≥n
- Las actualizaciones WebSocket en tiempo real fueron cr√≠ticas para el frontend ‚Äî los usuarios necesitan **ver a los agentes pensando**

**4. Los Safety Overrides previenen fallas catastr√≥ficas**
- Versi√≥n temprana: el LLM arbiter aprob√≥ una transacci√≥n de $50k a Nigeria (datos de prueba) ‚Äî falso negativo
- Se agreg√≥ regla hardcodeada: `composite_risk_score >= 80 ‚Üí forzar BLOCK`
- Lecci√≥n: **Los LLMs son herramientas, no or√°culos** ‚Äî los sistemas cr√≠ticos necesitan guardarra√≠les

**5. HITL es una decisi√≥n de producto, no solo una funcionalidad**
- Inicialmente trat√© HITL como "manejador de edge cases" ‚Äî enfoque equivocado
- La cola HITL es el **pipeline de datos de entrenamiento** para mejorar el modelo
- Insight de producci√≥n: 15% de transacciones se escalan ‚Üí retroalimentaci√≥n humana ‚Üí fine-tune de agentes de debate

### Errores y Correcciones de Rumbo

**‚ùå Error #1**: Intent√© construir el frontend antes de que el backend fuera estable ‚Üí 2 semanas perdidas en cambios de contrato API
**‚úÖ Correcci√≥n**: Desarrollo API-first con schemas OpenAPI, luego auto-generar tipos TypeScript

**‚ùå Error #2**: Us√© SQLite en desarrollo, PostgreSQL en producci√≥n ‚Üí bugs sutiles de serializaci√≥n de campos JSON
**‚úÖ Correcci√≥n**: Docker Compose con PostgreSQL desde el d√≠a 1 ‚Äî desarrollo = paridad con producci√≥n

**‚ùå Error #3**: Escrib√≠ 200 l√≠neas de connection pooling custom para WebSocket ‚Üí buggy y complejo
**‚úÖ Correcci√≥n**: El WebSocket manager integrado de FastAPI lo maneja ‚Äî **no reinventar la rueda**

**‚ùå Error #4**: Intent√© hacer agentes "inteligentes" pasando todo el historial de conversaci√≥n (10k tokens)
**‚úÖ Correcci√≥n**: Los agentes solo ven **su porci√≥n de entrada** del estado ‚Äî contexto m√°s peque√±o = m√°s r√°pido + m√°s barato

**‚ùå Error #5**: Omit√≠ escribir tests para l√≥gica de agregaci√≥n "simple" ‚Üí bugs en producci√≥n
**‚úÖ Correcci√≥n**: **Testear todo** ‚Äî incluso la l√≥gica "obvia" tiene edge cases (valores nulos, listas vac√≠as, bugs de timezone)

### Si Lo Construyera de Nuevo

**Har√≠a:**
- ‚úÖ Empezar con `uv` desde el d√≠a 1 (no migraci√≥n `pip` ‚Üí `poetry` ‚Üí `uv`)
- ‚úÖ Usar Pydantic para **gesti√≥n de configuraci√≥n** tambi√©n (no solo modelos de datos)
- ‚úÖ Implementar **feature flags** temprano (toggle debate on/off, RAG on/off para A/B testing)
- ‚úÖ Agregar **tracing distribuido** (OpenTelemetry) desde el inicio, no retrofitted
- ‚úÖ Escribir ADRs (Architecture Decision Records) ‚Äî me salv√≥ dos veces al revisar decisiones de dise√±o 3 meses despu√©s

**NO har√≠a:**
- ‚ùå Sobre-ingenier√≠a temprana ‚Äî el dise√±o inicial ten√≠a 12 agentes (excesivo), simplificado a 8
- ‚ùå Optimizar prematuramente ‚Äî pas√© 3 d√≠as optimizando queries de ChromaDB que no eran el cuello de botella
- ‚ùå Construir abstracciones custom sobre LangChain ‚Äî sus APIs cambian r√°pido, las abstracciones se vuelven pasivos

### Conclusi√≥n Clave

**Los sistemas LLM en producci√≥n son 20% ingenier√≠a de prompts, 80% ingenier√≠a de software.**
Lo dif√≠cil no es hacer que el LLM genere JSON ‚Äî es manejar errores async, gestionar consistencia de estado, testear comportamiento no-determin√≠stico y construir UIs que hagan que las decisiones de IA sean **confiables**.

Este proyecto me ense√±√≥ que **los agentes de IA son infraestructura**, no magia. Necesitan monitoreo, presupuestos de error, estrategias de rollback y el mismo rigor que cualquier sistema distribuido.

---

## üìÑ Licencia

Licencia MIT - ver archivo [LICENSE](LICENSE) para detalles.

---

## üë®‚Äçüíª Autor

**Miguel** - Ingeniero AI/ML
- Portafolio: [Your Portfolio URL]
- LinkedIn: [Your LinkedIn]
- GitHub: [@yourusername](https://github.com/yourusername)

---

## üôè Agradecimientos

- **Equipo LangChain** ‚Äî Por el framework de orquestaci√≥n LangGraph
- **Equipo FastAPI** ‚Äî Por el excelente framework de API async
- **Equipo ChromaDB** ‚Äî Por la base de datos vectorial ligera
- **Equipo Ollama** ‚Äî Por la inferencia LLM local

---

<div align="center">

**‚≠ê Dale estrella a este repo si te resulta √∫til!**

Construido con ‚ù§Ô∏è usando Python, FastAPI y LangGraph

</div>
